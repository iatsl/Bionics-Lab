{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R94pjX_-bQHa"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgNY-svxbSNl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Cu8VzAbdN2",
        "outputId": "e476b0a6-de50-433c-e8ee-a5241bc91e99",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "project_id = 'stairnet'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "# Test to see if dataset location is correct\n",
        "! gsutil ls -al gs://stairnet_bucket/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M927wwJHbeuG",
        "outputId": "d5b20494-dc94-41bc-bbe2-bcf6bb3823da",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse\n",
        "\n",
        "!mkdir data\n",
        "!gcsfuse --implicit-dirs stairnet_bucket data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "rhEP6TAtbNJu",
        "outputId": "4af34143-550d-4ba2-9b5b-c604fd189b42",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OApBOAe1fpH_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install timm\n",
        "!pip install  torchvideo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsFknIAYynfs"
      },
      "source": [
        "# FLAGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNh-oEmHmorI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['train_dataset_path'] = 'data/StairNet_Seq_5/SplitsVideo_numpy/Train/'\n",
        "FLAGS['val_dataset_path'] = 'data/StairNet_Seq_5/SplitsVideo_numpy/Val/'\n",
        "FLAGS['test_dataset_path'] = 'data/StairNet_Seq_5/SplitsVideo_numpy/Test/'\n",
        "FLAGS['batch_size'] = 8\n",
        "FLAGS['num_workers'] = 1 #- DataLoader worker (pid(s) 9180, 9220) exited unexpectedly\n",
        "FLAGS['learning_rate'] = 0.0001\n",
        "FLAGS['momentum'] = 0.5\n",
        "FLAGS['num_epochs'] = 10\n",
        "FLAGS['num_cores'] = 8\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6xVBoH3yxy8"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra1AsgYjyZZB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch_xla.utils.utils as xu\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "import torchvideo\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#os.environ['XLA_USE_BF16']=\"1\"\n",
        "#os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTmxZL5ymp8P",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self, n_classes, encoder_name = 'mobilenetv3_large_100', hidden_size= 256, rnn_hidden=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_labels = n_classes\n",
        "\n",
        "        # creating pretrained encoder model\n",
        "        self.encoder = timm.create_model(\n",
        "            encoder_name, \n",
        "            pretrained=True, \n",
        "            #features_only=True,\n",
        "        ).eval().requires_grad_(False)\n",
        "        \n",
        "        self.map_to_seq = nn.Linear(\n",
        "            self.encoder.conv_head.out_channels, hidden_size\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            hidden_size, rnn_hidden, bidirectional=True\n",
        "        )\n",
        "        self.dense = nn.Linear(2 * rnn_hidden, n_classes)\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = x.permute(0, 4, 1, 2, 3)\n",
        "        features = torch.stack([\n",
        "            self.encoder.forward_features(x[:, :, i]).squeeze(3).squeeze(2) for i in range(x.shape[2])\n",
        "        ])\n",
        "        return features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encode input sequence into a feature space \n",
        "        conv = self.encode(x) # (width, batch, feature)\n",
        "        seq = self.map_to_seq(conv)\n",
        "\n",
        "        recurrent, (hidden, cell) = self.lstm(seq)\n",
        "        # concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "\n",
        "        output = self.dense(hidden)\n",
        "        return output # shape: (batch, num_class)\n",
        "\n",
        "# Only instantiate model weights once in memory.\n",
        "FLAGS['model'] = xmp.MpModelWrapper(ClassificationModel(n_classes=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y75fNGrgodjW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "CLASS_NAMES  = {'IS': 0, 'ISLG': 1, 'LG': 2, 'LGIS': 3}\n",
        "\n",
        "class StairNetDataset(Dataset):\n",
        "    def __init__(self, folder, scale_img=True):\n",
        "        self.folder_name = folder\n",
        "        self.folder = os.listdir(folder)\n",
        "        self.scale = scale_img\n",
        "\n",
        "    def process_label(self, label):\n",
        "        ''' read label from filename'''\n",
        "        res = label.split('_')[-1].split('.')[0]\n",
        "        return res\n",
        "\n",
        "    def _create_one_hot(self, label):\n",
        "        ''' creating one-hot label from ordinary label '''\n",
        "        one_hot = np.zeros(shape=(len(CLASS_NAMES)))\n",
        "        one_hot[CLASS_NAMES[label]] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        labels = self.folder[idx]\n",
        "        sample = torch.from_numpy(\n",
        "            np.load(os.path.join(self.folder_name, labels)).astype('float32'))\n",
        "        label = self.process_label(labels)\n",
        "        if self.scale:\n",
        "            sample = sample.div(255.)\n",
        "        return sample, self._create_one_hot(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AC2YDV4FVLS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "FLAGS['train_dataset'] = StairNetDataset(FLAGS['train_dataset_path'])\n",
        "FLAGS['val_dataset'] = StairNetDataset(FLAGS['val_dataset_path'])\n",
        "FLAGS['test_dataset'] = StairNetDataset(FLAGS['test_dataset_path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization of a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b93zDo9GEQtF",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "img, label = FLAGS['val_dataset'][25]\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "for i in range(1, 5*1 +1):\n",
        "    fig.add_subplot(1, 5, i)\n",
        "    plt.imshow(img[i - 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rKgVB_ssYI9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def reduce(values):\n",
        "    '''    \n",
        "    Returns the average of the values.\n",
        "    Args:\n",
        "        values : list of any value which is calulated on each core \n",
        "    '''\n",
        "    return sum(values) / len(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train and Evaluation loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fGIP2qNIYm5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, criterion, optimizer, device, scheduler=None, MAX_GRAD_NORM=10):\n",
        "    model.train()\n",
        "\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "\n",
        "    for idx, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Train step'):\n",
        "        print(xm.get_ordinal(), device)\n",
        "        seq_batch = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "        #xm.master_print('Loaded sample')\n",
        "\n",
        "        output = model(seq_batch)\n",
        "        loss = criterion(labels, output)\n",
        "        #xm.master_print('Processed sample')\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        #if idx % 50 == 0:\n",
        "        #    loss_step = tr_loss/nb_tr_steps\n",
        "        #    print(f\"Training loss per {idx} training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        targets = torch.argmax(labels, dim=1) # shape (batch_size)\n",
        "        predictions = torch.argmax(output, dim=1) # shape (batch_size)\n",
        "        \n",
        "        tr_labels.extend(targets)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "\n",
        "        loss_reduced = xm.mesh_reduce('train_loss_reduce', \n",
        "                                      loss, \n",
        "                                      lambda vals: sum(vals) / len(vals))\n",
        "        xm.master_print(f'Train loss: {tr_loss} Added loss: {loss_reduced.item()}') \n",
        "        tr_loss += loss_reduced.item()\n",
        "\n",
        "    xm.master_print(f'Loss: {tr_loss} Nb steps: {nb_tr_steps}')\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    xm.master_print(f'Epoch loss: {epoch_loss}')\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    xm.master_print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    xm.master_print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    return epoch_loss, tr_accuracy\n",
        "\n",
        "def evaluate_epoch(test_dataloader, model, criterion, device, metric=False):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc='Evaluation step'):\n",
        "            seq_batch = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "            \n",
        "            outputs = model(seq_batch)\n",
        "            loss = criterion(labels, outputs)\n",
        "            \n",
        "            loss_reduced = xm.mesh_reduce('eval_loss_reduce', \n",
        "                                      loss, \n",
        "                                      lambda vals: sum(vals) / len(vals))\n",
        "            \n",
        "            eval_loss += loss_reduced.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            #if idx % 50 == 0:\n",
        "            #    loss_step = eval_loss/nb_eval_steps\n",
        "            #    print(f\"Validation loss per {idx} evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            targets = torch.argmax(labels, dim=1) # shape (batch_size)\n",
        "            predictions = torch.argmax(outputs, dim=1) # shape (batch_size)\n",
        "            \n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    xm.master_print(f\"Validation Loss: {eval_loss}\")\n",
        "    xm.master_print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    return eval_loss, eval_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afwo4H7kSd8P",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    global FLAGS\n",
        "    FLAGS = flags\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    # getting distrbuted train sampler\n",
        "    train_sampler = DistributedSampler(\n",
        "        dataset=flags['train_dataset'],\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    # distributed train dataloader\n",
        "    train_dataloader = DataLoader(\n",
        "        dataset=flags['train_dataset'],\n",
        "        batch_size=flags['batch_size'],\n",
        "        sampler=train_sampler,\n",
        "        num_workers=flags['num_workers'],\n",
        "        drop_last=True    \n",
        "    )\n",
        "    \n",
        "    # getting distributed val sampler\n",
        "    val_sampler = DistributedSampler(\n",
        "        dataset=flags['val_dataset'],\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    # distrbuted val dataloader\n",
        "    val_dataloader = DataLoader(\n",
        "        dataset=flags['val_dataset'],\n",
        "        batch_size=flags['batch_size'],\n",
        "        sampler=train_sampler,\n",
        "        num_workers=flags['num_workers'],\n",
        "        drop_last=True\n",
        "    )\n",
        "  \n",
        "    del train_sampler, val_sampler \n",
        "    gc.collect()\n",
        "\n",
        "    model = FLAGS['model'].to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam( #torch.optim.SGD(\n",
        "        model.parameters(), \n",
        "        lr=FLAGS['learning_rate'],\n",
        "        weight_decay=0.1\n",
        "    )\n",
        "    xm.master_print('Train start...')\n",
        "\n",
        "    for epoch in range(flags['num_epochs']):\n",
        "        # train step \n",
        "        train_parallel_loader = pl.ParallelLoader(\n",
        "            train_dataloader, [device]).per_device_loader(device)\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            train_dataloader=train_parallel_loader, \n",
        "            model=model, \n",
        "            criterion=criterion, \n",
        "            optimizer=optimizer, \n",
        "            device=device\n",
        "        )\n",
        "        xm.master_print(f'Train loss: {train_loss} \\t Train acc: {train_acc}')\n",
        "\n",
        "        del train_parallel_loader\n",
        "        gc.collect()\n",
        "\n",
        "        xm.master_print('Eval step...')\n",
        "        # evaluation step\n",
        "        val_parallel_loader = pl.ParallelLoader(\n",
        "            val_dataloader, [device]).per_device_loader(device)\n",
        "        val_loss, val_acc = evaluate_epoch(\n",
        "            test_dataloader=val_parallel_loader, \n",
        "            model=model, \n",
        "            criterion=criterion, \n",
        "            device=device, \n",
        "        )\n",
        "\n",
        "        del val_parallel_loader\n",
        "        gc.collect()\n",
        "\n",
        "        xm.save(model.state_dict(), f'model_weights.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IkEc-FkESzeT",
        "outputId": "f90f1759-90d2-4e21-fc06-6c135222759b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "vid_cl_torch_tpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
