{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIO5ZEvaFKFV",
        "outputId": "282228ab-8078-47f0-ef67-a554b997aef9"
      },
      "outputs": [],
      "source": [
        "project_id = 'stairnet-unlabeled'\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLcwYnDnBQ1h",
        "outputId": "cb5f4b3a-75ba-4f24-e42d-5f1d42b082d9"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al gs://"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXEoZeTyE4BI",
        "outputId": "e366bd50-dc14-429b-8462-3469f20fa962"
      },
      "outputs": [],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNJ7aRFWE7eB",
        "outputId": "0650c9e9-2932-429c-d6cd-a4421ca3bad8"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!gcsfuse --implicit-dirs stairnet_unlabeled_bucket data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3SyxAzS-AK2",
        "outputId": "daa240e7-bef5-4659-dcb9-55377d70fe60"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G72nuPfSD1t6",
        "outputId": "c7e24583-2ed5-44f3-cc53-4233c359c15f"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import gc\n",
        "import math, re, os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoUdP92D3zt",
        "outputId": "dcc77781-a3c9-40e8-8043-6307c2dfdb1a"
      },
      "outputs": [],
      "source": [
        "def create_distribution_strategy():\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    except ValueError: \n",
        "        strategy = tf.distribute.MirroredStrategy()\n",
        "    print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "    return strategy\n",
        "\n",
        "strategy = create_distribution_strategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generating TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9ndGVm5D5jC"
      },
      "outputs": [],
      "source": [
        "# Videos in the test split\n",
        "TEST_VIDEOS = [\n",
        "    'IMG_02_1', \n",
        "    'IMG_02_4', \n",
        "    'IMG_05_1', \n",
        "    'IMG_11_1', \n",
        "    'IMG_14_2', \n",
        "    'IMG_20_1',\n",
        "]\n",
        "\n",
        "# Mapping class to numeric representation\n",
        "CLASS_MAP = {'IS': 0 , 'ISLG': 1, 'LG': 2, 'LGIS': 3}  \n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "SEED_NUMBER = 42\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Base folder path\n",
        "FOLDER_PATH = 'data/StairNet/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz40hb7nEETV"
      },
      "outputs": [],
      "source": [
        "def get_video_number(file_name):\n",
        "    '''\n",
        "        parse video number from string\n",
        "        input: [IMG_#_#] frame # #CLASS#.jpg\n",
        "        output: IMG_#_#\n",
        "    '''\n",
        "    return file_name.split(' ')[0].replace(\"['\", '').replace(\"']\", '').replace(\"'\", '')\n",
        "\n",
        "def get_video_paths(folder_path, selected_videos):\n",
        "    ''' for each sample generate full frame path '''\n",
        "    img_paths = {vid_name: list() for vid_name in selected_videos}\n",
        "    for class_path in os.listdir(folder_path):\n",
        "        for img_sample in tqdm(os.listdir(os.path.join(folder_path, class_path))):\n",
        "            curr_sample = os.path.join(folder_path, class_path, img_sample)\n",
        "            #print(get_video_number(curr_sample).split('/')[-1])\n",
        "            if get_video_number(curr_sample).split('/')[-1] in selected_videos:\n",
        "                img_paths[get_video_number(curr_sample).split('/')[-1]].append(curr_sample)\n",
        "    print()\n",
        "    print(len(img_paths))\n",
        "    return img_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQvgIt17GcP2",
        "outputId": "a207f1c9-5d86-4ef6-c456-7911eb78fcc2"
      },
      "outputs": [],
      "source": [
        "img_paths = get_video_paths(FOLDER_PATH, TEST_VIDEOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbZC7jZtcVkg",
        "outputId": "f747d4c8-71fc-46af-dbbd-62aeb44ded0a"
      },
      "outputs": [],
      "source": [
        "for vid_name in img_paths.keys():\n",
        "    print(vid_name, len(img_paths[vid_name]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP70tKGsHxiV"
      },
      "outputs": [],
      "source": [
        "def load_image(filename, img_load='pil', img_size=(256, 256)):\n",
        "  ''' reading frame from filename'''\n",
        "  if img_load == 'cv2':\n",
        "    img = cv2.imread(filename)\n",
        "    img.resize(img_size)\n",
        "  elif img_load == 'pil':\n",
        "    img = Image.open(filename)\n",
        "    img = img.resize(img_size, Image.ANTIALIAS)  \n",
        "  return np.array(img)\n",
        "\n",
        "def read_sample(img_path, img_size = 256):\n",
        "  ''' reading sample from img_path'''\n",
        "  img = load_image(img_path)\n",
        "  labels = np.array(CLASS_MAP[img_path.split('/')[-1].split(' ')[-1].split('.')[0]])\n",
        "  return img, labels\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def generate_seq_dataset(img_arr):\n",
        "    # iterate over video in dataset\n",
        "    counter = 0\n",
        "    for vid_name in list(img_arr.keys())[-1:]:\n",
        "        print(vid_name)\n",
        "        writer = tf.io.TFRecordWriter(f'drive/MyDrive/Baseline_samples/test_{vid_name}.tfrecord')\n",
        "        for img in tqdm(img_arr[vid_name]): # for each sample in video generate sample\n",
        "            np_sample, labels = read_sample(img, img_size=256)\n",
        "            assert np_sample.shape == (256, 256, 3)\n",
        "            feature = {\n",
        "                'label': _bytes_feature(labels.tobytes()),\n",
        "                'image': _bytes_feature(np_sample.tobytes())\n",
        "            }\n",
        "            # writing to tfrecord file\n",
        "            tf_example = tf.train.Example(features = tf.train.Features(feature=feature))\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "            del np_sample, labels, tf_example\n",
        "            gc.collect()\n",
        "            counter += 1\n",
        "        writer.close()\n",
        "        del writer\n",
        "        gc.collect()\n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo0Eq30qI9jv",
        "outputId": "3aa7c786-d2f7-43a1-f665-97e1074bcbb0"
      },
      "outputs": [],
      "source": [
        "counter = generate_seq_dataset(img_paths)\n",
        "# counter = 12907 + 5573 + 11838 + 9364 + 11401 + 5652\n",
        "print('Number of frames: ', counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmUoQePZeARN"
      },
      "outputs": [],
      "source": [
        "# generated tfrecords of the test split videos\n",
        "TEST_FILENAMES = [\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_02_1.tfrecord',\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_02_4.tfrecord',\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_05_1.tfrecord',\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_11_1.tfrecord',\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_14_2.tfrecord',\n",
        "    'drive/MyDrive/Baseline_samples/test_IMG_20_1.tfrecord'   \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUs0jVu5I7ji",
        "outputId": "a12f0c13-4b84-49fb-bd70-6e34d67ba26f"
      },
      "outputs": [],
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.io.decode_raw(image_data, tf.uint8)\n",
        "    # image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    # image = image_data\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
        "    image = tf.image.random_crop(value=image, size=(224, 224, 3))\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    #label = tf.cast(example['label'], tf.int32)\n",
        "    label = tf.io.decode_raw(example['label'], 'int32')[0]\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # for hyperparameter testing using random seed to shuffle the data the same to elimite this variable from results\n",
        "    dataset = dataset.shuffle(counter//10, seed=SEED_NUMBER, reshuffle_each_iteration=None)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset \n",
        "\n",
        "\n",
        "BATCH_SIZE = 157\n",
        "TEST_STEPS = -(-counter // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "print(' {} test images'.format(counter))\n",
        "print('Number of test steps: ', TEST_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hbdqdQPkM9J",
        "outputId": "74db7bd5-c171-4700-adec-38b654bb609a"
      },
      "outputs": [],
      "source": [
        "!ls drive/MyDrive/supervised_pretraining/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fPN4Tp5FLxK"
      },
      "outputs": [],
      "source": [
        "# with tpu_strategy.scope():\n",
        "#     model = tf.keras.models.load_model('./drive/MyDrive/supervised_pretraining/StairNet_v2.h5', compile=True)\n",
        "\n",
        "MODEL_PATH = 'drive/MyDrive/supervised_pretraining/StairNet_v3.h5'\n",
        "model = keras.models.load_model(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1AC7rlUFtn_",
        "outputId": "420fb14c-bf30-4fd7-ddb0-9f2fa4078af5"
      },
      "outputs": [],
      "source": [
        "cmdataset = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "cm_correct_labels = next(iter(labels_ds.batch(counter))).numpy() # get everything as one batch\n",
        "cm_probabilities = model.predict(images_ds, steps=TEST_STEPS)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe6YHMEdF0yj",
        "outputId": "8db03d52-e13b-40bf-ffe6-b0535c4fb9e7"
      },
      "outputs": [],
      "source": [
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASS_MAP)))\n",
        "# score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS_MAP)), average='weighted')\n",
        "# precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS_MAP)), average='weighted')\n",
        "# recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASS_MAP)), average='weighted')\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n",
        "# display_confusion_matrix(cmat, score, precision, recall)\n",
        "print('accuracy: {:.5f}, f1 score: {:.5f}, precision: {:.5f}, recall: {:.5f}'.format(accuracy, score, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "L1QcKrmuF8_W",
        "outputId": "27ab3e4e-bfd5-4e9a-f7c1-a2da22c0ccf9"
      },
      "outputs": [],
      "source": [
        "ax = plt.subplot()\n",
        "sns.heatmap(cmat, annot=True, fmt='.2%', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title(f'Normalized Confusion Matrix  \\nAccuracy: {accuracy} F1: {score} \\nPrecision: {precision} Recall: {recall}'); \n",
        "ax.xaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']); ax.yaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']);\n",
        "\n",
        "plot_location = f\"StairNetv3(Dima)_image_validation_test.jpg\"\n",
        "plt.savefig(plot_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YetfOfFO-5QI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "VidClassification_baseline.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
